[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Analysis in Medical Research Using R",
    "section": "",
    "text": "Welcome to the Statistical Analysis in Medical Research Using R tutorial series. This series is designed to introduce you to the fundamental concepts of statistical analysis using the R programming language, with a focus on applications in medical research.\n\n\nIn this series, you will learn how to:\n\nUnderstand the importance of statistical analysis in medical research\nPerform basic data manipulation and visualization in R\nApply descriptive and inferential statistics to medical data\nInterpret the results of statistical analyses in the context of medical research\n\n\n\n\nBelow are the chapters included in this series. Each chapter builds on the previous one, so it’s recommended to go through them in order.\n\n\nIn the first chapter, we provide an overview of the role of statistics in medical research. You will learn about different types of data, common statistical terms, and why statistical analysis is crucial in the medical field.\n\n\n\nThe second chapter introduces you to the basics of programming in R. You will learn how to install R and RStudio, understand R syntax, and perform basic operations and data manipulation. This chapter sets the foundation for more advanced topics covered later in the series.\n\n\n\n\nTo get started, ensure you have R and RStudio installed on your computer. If not, follow the installation instructions provided in Chapter 02.",
    "crumbs": [
      "Home",
      "Statistical Analysis in Medical Research Using R"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Statistical Analysis in Medical Research Using R",
    "section": "",
    "text": "In this series, you will learn how to:\n\nUnderstand the importance of statistical analysis in medical research\nPerform basic data manipulation and visualization in R\nApply descriptive and inferential statistics to medical data\nInterpret the results of statistical analyses in the context of medical research",
    "crumbs": [
      "Home",
      "Statistical Analysis in Medical Research Using R"
    ]
  },
  {
    "objectID": "index.html#chapters",
    "href": "index.html#chapters",
    "title": "Statistical Analysis in Medical Research Using R",
    "section": "",
    "text": "Below are the chapters included in this series. Each chapter builds on the previous one, so it’s recommended to go through them in order.\n\n\nIn the first chapter, we provide an overview of the role of statistics in medical research. You will learn about different types of data, common statistical terms, and why statistical analysis is crucial in the medical field.\n\n\n\nThe second chapter introduces you to the basics of programming in R. You will learn how to install R and RStudio, understand R syntax, and perform basic operations and data manipulation. This chapter sets the foundation for more advanced topics covered later in the series.",
    "crumbs": [
      "Home",
      "Statistical Analysis in Medical Research Using R"
    ]
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Statistical Analysis in Medical Research Using R",
    "section": "",
    "text": "To get started, ensure you have R and RStudio installed on your computer. If not, follow the installation instructions provided in Chapter 02.",
    "crumbs": [
      "Home",
      "Statistical Analysis in Medical Research Using R"
    ]
  },
  {
    "objectID": "Chapter01_Introduction.html",
    "href": "Chapter01_Introduction.html",
    "title": "R Basics",
    "section": "",
    "text": "This section covers everything you need to perform statistical analysis using R(2024). Similar to other programming languages, R has a base package and an Integrated Development Environment (IDE). The base package allows you to run R code on your computer, while R Studio is an IDE specifically designed for developing R programs and packages.\n\n\nThe R base package can be downloaded from the official R website. Once on the website, select the precompiled binary for your operating system, download the file, and install it. To verify that R has been successfully installed, open your command prompt (cmd) or terminal and type R to start the R console. To exit the R console, type q().\n$ R\n\nR version 4.4.0 (2024-04-24) -- \"Puppy Cup\"\nCopyright (C) 2024 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n&gt; q()\n\n\n\nRStudio is an essential tool for anyone working with the R programming language. It serves as an integrated development environment (IDE) that makes working with R more efficient and user-friendly. Here’s what you need to know:\n\n\nRStudio is a flexible, multifunctional open-source IDE that serves as a graphical front-end for working with R (version 3.0.1 or higher). Additionally, it supports other programming languages like Python and SQL. Key features of RStudio include a user-friendly interface, the ability to write and save reusable scripts, and easy access to imported data and created objects such as variables and functions. It provides exhaustive help on any object, offers code autocompletion, and facilitates project organization and collaboration. Users can preview plots, switch between the terminal and console, and track their operational history, making it an indispensable tool for data analysis and programming.\n\n\n\nTo install RStudio, begin by visiting the official RStudio website. Scroll down to locate the download buttons for RStudio Desktop. Select the precompiled binary appropriate for your operating system, download the file, and install it.\n\n\n\n\n\nDataCamp’s RStudio Tutorial: A comprehensive guide for beginners.\nDataquest’s Getting Started with R and RStudio: Learn key features and start programming in R.\nGitHub Pages: Introduction to RStudio: Fundamentals of RStudio for scientific projects.\nIntroduction to R and RStudio (GitBook): Best practices for organizing code using RStudio.\nRStudio for the Total Beginner: An accessible introduction to RStudio for the total beginner.\n\n\n\n\nLearning Statistics with R\nStatistical Methods in Medical Research\n\n\n\n\n\nDescriptive statistics is a branch of statistics that focuses on summarizing and describing the features of a dataset. It provides simple summaries about the sample and the measures, offering a way to present data in a meaningful and understandable form. The origins of descriptive statistics date back to the early days of statistical science, where it served as the foundational method for analyzing data.\nHistory:\nThe roots of descriptive statistics can be traced back to ancient civilizations, such as the Babylonians and Egyptians, who used basic statistical methods to manage agricultural data, censuses, and astronomical information. However, the formal development of descriptive statistics began in the 17th and 18th centuries. John Graunt, an English demographer, is often credited with laying the groundwork for statistical analysis through his work on mortality rates in the 1660s. His pioneering efforts in collecting and analyzing data led to the birth of modern statistics.\nIn the 18th century, the field was further advanced by the work of mathematicians like Pierre-Simon Laplace and Carl Friedrich Gauss, who developed key statistical concepts and methods. The 19th and 20th centuries saw the emergence of more sophisticated statistical techniques and the formalization of the discipline. Descriptive statistics evolved to include a variety of measures and graphical representations that remain fundamental to data analysis today.\nExamples:\n\nMeasures of Central Tendency:\n\nMean: The arithmetic average of a set of numbers. For example, in a dataset of test scores (80, 85, 90, 75, 95), the mean score is calculated as (80 + 85 + 90 + 75 + 95) / 5 = 85.\nMedian: The middle value in a dataset when the numbers are arranged in ascending order. In the test scores example, the median score is 85.\nMode: The most frequently occurring value in a dataset. If a dataset of test scores is (80, 85, 85, 90, 95), the mode is 85.\n\nMeasures of Dispersion:\n\nRange: The difference between the highest and lowest values in a dataset. For test scores (75, 80, 85, 90, 95), the range is 95 - 75 = 20.\nVariance: A measure of the spread of a dataset. It is the average of the squared differences from the mean. For the test scores, the variance can be calculated by finding the mean, subtracting each score from the mean, squaring the result, and then averaging those squared differences.\nStandard Deviation: The square root of the variance, representing the average amount each value in the dataset differs from the mean. It provides insight into the dataset’s overall variability.\n\nGraphical Representations:\n\nHistograms: Bar graphs that represent the frequency distribution of a dataset. They help in visualizing the shape and spread of data.\nBox Plots: Graphical representations that show the distribution of a dataset based on a five-number summary: minimum, first quartile, median, third quartile, and maximum. Box plots highlight the central tendency and variability, as well as potential outliers.\nPie Charts: Circular charts divided into sectors representing proportions of the whole. They are useful for displaying categorical data and comparing parts of a whole.\n\n\nDescriptive statistics is essential in various fields, including economics, psychology, and social sciences, where it aids in making data-driven decisions. By providing a clear summary of data through measures of central tendency, dispersion, and graphical representations, descriptive statistics helps researchers and analysts interpret and communicate their findings effectively.\n\n\nTo perform descriptive statistics, we need to assign some numbers to a variable. This can be done using the `c()` function, which stands for combine.\n\nmy_numbers &lt;- c(1,2,3,4)\n\nThere a few other handy ways to make numbers. We can use seq() to make a sequence. Here’s making the numbers from 1 to 100\n\none_to_one_hundred &lt;- seq(1,100,1)\n\nWe can repeat things, using rep. Here’s making 10 5s, and 25 1s:\n\nrep(10,5)\n\n[1] 10 10 10 10 10\n\nrep(1,25)\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\nall_together_now &lt;- c(rep(10,5),rep(1,25)) \n\n\n\n\nLet’s work with the numbers 1 to 256. First, we’ll use the `sum()` function to add them up.\n\none_to_one_hundred &lt;- seq(1,100,1)\nsum(one_to_one_hundred)\n\n[1] 5050\n\n\n\n\n\nWe put 100 numbers into the variable one_to_one_hundred. We know how many numbers there are in there. How can we get R to tell us? We use length() for that.\n\nlength(one_to_one_hundred)\n\n[1] 100\n\n\n\n\n\n\n\nRemember the mean of some numbers is their sum, divided by the number of numbers. We can compute the mean like this:\n\nsum(one_to_one_hundred)/length(one_to_one_hundred)\n\n[1] 50.5\n\n\nOr, we could just use the mean() function like this:\n\nmean(one_to_one_hundred)\n\n[1] 50.5\n\n\n\n\n\nThe median is the number that lies exactly in the middle of a sorted list of numbers. If the list has an even number of elements, the median is calculated as the average of the two middle numbers. You can use the median() function to find it. For example, in a list of three numbers, the middle number is 2, so the median is 2.\n\nmedian(c(1,2,3))\n\n[1] 2\n\n\n\n\n\nR does not have a built-in function for calculating the mode. You will need to write one yourself. Here is an example of how to create a mode function and use it. Remember, the mode is the number that appears most frequently in a dataset. In the example below, 1 occurs the most often, so the mode is 1.\n\nmode &lt;- function(x) {\n  ux &lt;- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\nmode(c(1,1,1,1,1,1,1,2,3,4))\n\n[1] 1\n\n\n\n\n\n\nWe often want to understand how much the numbers vary. To describe this variability, we look at descriptive statistics such as range, variance, the standard deviation, and others.\nFirst, let’s remind ourselves what variation looks like (it refers to differences among numbers). We’ll sample 1000 numbers from a normal distribution with a mean of 101 and a standard deviation of 35. Then, we’ll create a histogram to visualize the variation around the mean of 10.\n\nsample_numbers &lt;- rnorm(1000,101,35)\nhist(sample_numbers)\n\n\n\n\n\n\n\n\n\n\nThe range is the minimum and maximum values in the set, we use the range function.\n\nrange(sample_numbers)\n\n[1] -20.99564 199.26425\n\n\n\n\n\nWe can find the sample variance using var().\n\nvar(sample_numbers)\n\n[1] 1355.992\n\n\n\n\n\nWe find the sample standard deviation us SD.\n\nsd(sample_numbers)\n\n[1] 36.8238\n\n\nRemember that the standard deviation is just the square root of the variance, see:\n\nsqrt(var(sample_numbers))\n\n[1] 36.8238\n\n\n\n\n\n\nsample_numbers &lt;- rnorm(1000,101,35)\n\nsum(sample_numbers)\n\n[1] 102476\n\nlength(sample_numbers)\n\n[1] 1000\n\nmean(sample_numbers)\n\n[1] 102.476\n\nmedian(sample_numbers)\n\n[1] 102.2365\n\nmode(sample_numbers)\n\n[1] 109.5741\n\nrange(sample_numbers)\n\n[1]  -5.618234 220.171208\n\nvar(sample_numbers)\n\n[1] 1237.785\n\nsd(sample_numbers)\n\n[1] 35.18217\n\n\n\n\n\n\nIn some instances, a single variable may contain a number of values, which can be analyzed using the aforementioned functions to obtain descriptive statistics. Conversely, in the majority of cases encountered in this course, a data frame comprising numerous numerical values representing different conditions will be employed. In such instances, it is necessary to identify descriptive statistics for each set of values within each condition.\nFortunately, the R programming language is highly adept at performing this task in a single operation. To illustrate this concept, consider the following example. A data frame containing 10 numbers for each condition will be created. There are 10 conditions, each labeled A, B, C, D, E, F, G, H, I, and J.\n\nscores &lt;- rnorm(100,10,5)\nconditions &lt;- rep(c(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"), each =10)\nmy_df &lt;- data.frame(conditions,scores)\n\nA review of the my_df data frame reveals that it contains 100 rows. Each row represents a distinct condition, with a label in the conditions column and 10 scores for that condition in the scores column. One might inquire as to the mean of the scores in each condition. In order to obtain the mean of the scores for each condition, one must find the mean of 10 scores.\nThe slow way to do it would be like this:\n\nmean(my_df[my_df$conditions==\"A\",]$scores)\n\n[1] 8.383671\n\nmean(my_df[my_df$conditions==\"B\",]$scores)\n\n[1] 9.801244\n\nmean(my_df[my_df$conditions==\"C\",]$scores)\n\n[1] 11.44105\n\n# and then keep going\n\nIt is evident that no individual or entity is willing to assume the responsibility of performing this task. It is therefore prudent to encapsulate this functionality, and R provides us with the necessary tools to automate this functionality.\n\n\nWe can easily do everything all at once using the group_by and summarise function from the dplyr package. Just watch\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmy_df %&gt;%\n  group_by(conditions) %&gt;%\n  summarise(means = mean(scores))\n\n# A tibble: 10 × 2\n   conditions means\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 A           8.38\n 2 B           9.80\n 3 C          11.4 \n 4 D           7.97\n 5 E           7.78\n 6 F          12.1 \n 7 G           9.83\n 8 H           9.98\n 9 I          12.8 \n10 J           9.42\n\n\nA few points require further consideration. Firstly, the printout of this was of an inferior quality. A solution to this issue is to create a new variable containing the results of the code and then use the knitr::kable function to print the variable in a more aesthetically pleasing manner when the document is compiled.\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\n\n\n\n\nA\n8.383671\n\n\nB\n9.801244\n\n\nC\n11.441048\n\n\nD\n7.974663\n\n\nE\n7.781818\n\n\nF\n12.135713\n\n\nG\n9.825402\n\n\nH\n9.977129\n\n\nI\n12.819841\n\n\nJ\n9.419859\n\n\n\n\n\n\n\n\nThe most advantageous aspect of the dplyr method is that it permits the addition of multiple functions, resulting in the generation of multiple summary statistics in a unified format. To illustrate this, consider the calculation of the standard deviation:\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores),\n                         sds = sd(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\nsds\n\n\n\n\nA\n8.383671\n4.628645\n\n\nB\n9.801244\n5.308608\n\n\nC\n11.441048\n3.989864\n\n\nD\n7.974663\n3.307205\n\n\nE\n7.781818\n4.259350\n\n\nF\n12.135713\n5.319706\n\n\nG\n9.825402\n5.487877\n\n\nH\n9.977129\n3.941479\n\n\nI\n12.819841\n3.605219\n\n\nJ\n9.419859\n3.559865\n\n\n\n\n\nFurthermore, the minimum and maximum values will be included.\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores),\n                         sds = sd(scores),\n                         min = min(scores),\n                         max = max(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\nsds\nmin\nmax\n\n\n\n\nA\n8.383671\n4.628645\n0.7328838\n13.89646\n\n\nB\n9.801244\n5.308608\n3.5712960\n19.72275\n\n\nC\n11.441048\n3.989864\n4.7661719\n17.85150\n\n\nD\n7.974663\n3.307205\n2.5534580\n15.31436\n\n\nE\n7.781818\n4.259350\n2.3406561\n14.87115\n\n\nF\n12.135713\n5.319706\n1.7331240\n19.69039\n\n\nG\n9.825402\n5.487877\n1.1443116\n18.16272\n\n\nH\n9.977129\n3.941479\n4.6518956\n14.60040\n\n\nI\n12.819841\n3.605219\n7.3310402\n18.92470\n\n\nJ\n9.419859\n3.559865\n3.6327248\n15.14616\n\n\n\n\n\n\n\n\n\nHaving established the methodology for obtaining descriptive statistics from R, we may now proceed to apply this methodology to a real data set. We will now proceed to inquire about the gapminder data.\n\nlibrary(gapminder)\ngapminder_df &lt;- gapminder\n\nNote: The code will only function properly if the gapminder package has been installed. It is imperative that the user is connected to the internet prior to commencing the installation process. To do so, navigate to the Packages tab, located in the bottom right panel, and select the option to install. Subsequently, a search for the gapminder package should be conducted, after which it should be selected and installed.\n\n\nCopy the code from the last part of descriptives using dplyr, then change the names like this:\n\nsummary_df &lt;- gapminder_df %&gt;%\n               group_by(continent) %&gt;%\n               summarise(means = mean(lifeExp),\n                         sds = sd(lifeExp),\n                         min = min(lifeExp),\n                         max = max(lifeExp))\n\nknitr::kable(summary_df)\n\n\n\n\ncontinent\nmeans\nsds\nmin\nmax\n\n\n\n\nAfrica\n48.86533\n9.150210\n23.599\n76.442\n\n\nAmericas\n64.65874\n9.345088\n37.579\n80.653\n\n\nAsia\n60.06490\n11.864532\n28.801\n82.603\n\n\nEurope\n71.90369\n5.433178\n43.585\n81.757\n\n\nOceania\n74.32621\n3.795611\n69.120\n81.235\n\n\n\n\n\n\n\n\n\nComplete the generalization exercise described in your R Markdown document for this lab.\n\nWhat is the mean, standard deviation, minimum and maximum life expectancy for all the gapminder data (across all the years and countries). Hint: do not use group_by\nWhat is the mean, standard deviation, minimum and maximum life expectancy for all of the continents in 2007, the most recent year in the dataset. Hint: add another pipe using filter(year==2007) %&gt;%\n\n\n\n\nComplete the writing assignment described in your R Markdown document for this lab. When you have finished everything. Knit the document and hand in your stuff (you can submit your .RMD file to blackboard if it does not knit.)\nYour writing assignment is to answer these questions in full sentences using simple plain langauge:\n\nDefine the mode.\nExplain what would need to happen in order for a set of numbers to have two modes\nDefine the median\nDefine the mean\nDefine the range\nWhen calculating the standard deviation, explain what the difference scores represent\nExplain why the difference scores are squared when calculating the standard deviation\nIf one set of numbers had a standard deviation of 5, and another had a standard deviation of 10, which set of numbers would have greater variance, explain why.\n\n\n\n\nNow let’s use a real dataset to calculate the same measures of central tendency and variability as in the previous example, but with the addition of a histogram to visualize the distribution and relate back to the descriptive statistics. Here is a link to the life expectancy dataset we used for our graphing tutorial. It is named life_expectancy.csv.\nSuppose we wanted to know about life expectancy around the world in 2018. This will include calculating descriptive statistics and graphing a histogram to examine the distribution of our data. R allows us to handle these tasks efficiently with a few lines of code.\n\n\n\nLoad the Data:\n\nFirst, ensure you have the dataset life_expectancy.csv in your working directory.\nLoad the data into R.\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load the data\nlife_expectancy &lt;- read.csv(\"data/life_expectancy.csv\")\nCalculate Descriptive Statistics:\n\nCalculate the measures of central tendency (mean, median, mode) and measures of variability (range, standard deviation, variance) for life expectancy in 2018.\n\n# Filter for the year 2018\nlife_2018 &lt;- life_expectancy %&gt;% filter(Year == 2018) %&gt;% select(life_expectancy)\n\n# Calculate descriptive statistics\n\n# Summarize the results\nCreate a Histogram:\n\nPlot a histogram to visualize the distribution of life expectancy in 2018, and overlay a normal curve.\n\n# Plot the histogram with a normal curve\nggplot(life_2018, aes(x = life_expectancy)) +\n  geom_histogram(aes(y = ..density..), binwidth = 2, fill = \"skyblue\", color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = mean_life, sd = sd_life), color = \"red\", size = 1) +\n  labs(title = \"Histogram of Life Expectancy in 2018\",\n       x = \"Life Expectancy\",\n       y = \"Density\") +\n  theme_minimal()\n\nThis process will produce a histogram displaying the distribution of life expectancy in 2018 with a superimposed normal curve for comparison.\n\n\n\nThink about what the mean, median, and mode indicate about the shape of the distribution. Is this confirmed when you look at the histogram? How does the shape of this distribution compare to the symmetrical normal distribution that is superimposed over it? The histogram helps visualize the skewness and spread of the data, providing a deeper understanding of the life expectancy distribution in 2018.\n\n\n\n\n\n\nUsing the life expectancy data set, produce a table of output showing the descriptive statistics (measures of central tendency and variability) for both years 1800 and 1934 (during the Great Depression).\nPlot histograms of life expectancy for both years. How are these distributions different? (Hint: Plot these on the same axes so that they are comparable).",
    "crumbs": [
      "Introduction",
      "R Basics"
    ]
  },
  {
    "objectID": "Chapter01_Introduction.html#installing",
    "href": "Chapter01_Introduction.html#installing",
    "title": "R Basics",
    "section": "",
    "text": "The R base package can be downloaded from the official R website. Once on the website, select the precompiled binary for your operating system, download the file, and install it. To verify that R has been successfully installed, open your command prompt (cmd) or terminal and type R to start the R console. To exit the R console, type q().\n$ R\n\nR version 4.4.0 (2024-04-24) -- \"Puppy Cup\"\nCopyright (C) 2024 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n&gt; q()",
    "crumbs": [
      "Introduction",
      "R Basics"
    ]
  },
  {
    "objectID": "Chapter01_Introduction.html#introduction-to-rstudio",
    "href": "Chapter01_Introduction.html#introduction-to-rstudio",
    "title": "R Basics",
    "section": "",
    "text": "RStudio is an essential tool for anyone working with the R programming language. It serves as an integrated development environment (IDE) that makes working with R more efficient and user-friendly. Here’s what you need to know:\n\n\nRStudio is a flexible, multifunctional open-source IDE that serves as a graphical front-end for working with R (version 3.0.1 or higher). Additionally, it supports other programming languages like Python and SQL. Key features of RStudio include a user-friendly interface, the ability to write and save reusable scripts, and easy access to imported data and created objects such as variables and functions. It provides exhaustive help on any object, offers code autocompletion, and facilitates project organization and collaboration. Users can preview plots, switch between the terminal and console, and track their operational history, making it an indispensable tool for data analysis and programming.\n\n\n\nTo install RStudio, begin by visiting the official RStudio website. Scroll down to locate the download buttons for RStudio Desktop. Select the precompiled binary appropriate for your operating system, download the file, and install it.",
    "crumbs": [
      "Introduction",
      "R Basics"
    ]
  },
  {
    "objectID": "Chapter01_Introduction.html#additional-resources",
    "href": "Chapter01_Introduction.html#additional-resources",
    "title": "R Basics",
    "section": "",
    "text": "DataCamp’s RStudio Tutorial: A comprehensive guide for beginners.\nDataquest’s Getting Started with R and RStudio: Learn key features and start programming in R.\nGitHub Pages: Introduction to RStudio: Fundamentals of RStudio for scientific projects.\nIntroduction to R and RStudio (GitBook): Best practices for organizing code using RStudio.\nRStudio for the Total Beginner: An accessible introduction to RStudio for the total beginner.\n\n\n\n\nLearning Statistics with R\nStatistical Methods in Medical Research",
    "crumbs": [
      "Introduction",
      "R Basics"
    ]
  },
  {
    "objectID": "Chapter01_Introduction.html#descriptive-statistics",
    "href": "Chapter01_Introduction.html#descriptive-statistics",
    "title": "R Basics",
    "section": "",
    "text": "Descriptive statistics is a branch of statistics that focuses on summarizing and describing the features of a dataset. It provides simple summaries about the sample and the measures, offering a way to present data in a meaningful and understandable form. The origins of descriptive statistics date back to the early days of statistical science, where it served as the foundational method for analyzing data.\nHistory:\nThe roots of descriptive statistics can be traced back to ancient civilizations, such as the Babylonians and Egyptians, who used basic statistical methods to manage agricultural data, censuses, and astronomical information. However, the formal development of descriptive statistics began in the 17th and 18th centuries. John Graunt, an English demographer, is often credited with laying the groundwork for statistical analysis through his work on mortality rates in the 1660s. His pioneering efforts in collecting and analyzing data led to the birth of modern statistics.\nIn the 18th century, the field was further advanced by the work of mathematicians like Pierre-Simon Laplace and Carl Friedrich Gauss, who developed key statistical concepts and methods. The 19th and 20th centuries saw the emergence of more sophisticated statistical techniques and the formalization of the discipline. Descriptive statistics evolved to include a variety of measures and graphical representations that remain fundamental to data analysis today.\nExamples:\n\nMeasures of Central Tendency:\n\nMean: The arithmetic average of a set of numbers. For example, in a dataset of test scores (80, 85, 90, 75, 95), the mean score is calculated as (80 + 85 + 90 + 75 + 95) / 5 = 85.\nMedian: The middle value in a dataset when the numbers are arranged in ascending order. In the test scores example, the median score is 85.\nMode: The most frequently occurring value in a dataset. If a dataset of test scores is (80, 85, 85, 90, 95), the mode is 85.\n\nMeasures of Dispersion:\n\nRange: The difference between the highest and lowest values in a dataset. For test scores (75, 80, 85, 90, 95), the range is 95 - 75 = 20.\nVariance: A measure of the spread of a dataset. It is the average of the squared differences from the mean. For the test scores, the variance can be calculated by finding the mean, subtracting each score from the mean, squaring the result, and then averaging those squared differences.\nStandard Deviation: The square root of the variance, representing the average amount each value in the dataset differs from the mean. It provides insight into the dataset’s overall variability.\n\nGraphical Representations:\n\nHistograms: Bar graphs that represent the frequency distribution of a dataset. They help in visualizing the shape and spread of data.\nBox Plots: Graphical representations that show the distribution of a dataset based on a five-number summary: minimum, first quartile, median, third quartile, and maximum. Box plots highlight the central tendency and variability, as well as potential outliers.\nPie Charts: Circular charts divided into sectors representing proportions of the whole. They are useful for displaying categorical data and comparing parts of a whole.\n\n\nDescriptive statistics is essential in various fields, including economics, psychology, and social sciences, where it aids in making data-driven decisions. By providing a clear summary of data through measures of central tendency, dispersion, and graphical representations, descriptive statistics helps researchers and analysts interpret and communicate their findings effectively.\n\n\nTo perform descriptive statistics, we need to assign some numbers to a variable. This can be done using the `c()` function, which stands for combine.\n\nmy_numbers &lt;- c(1,2,3,4)\n\nThere a few other handy ways to make numbers. We can use seq() to make a sequence. Here’s making the numbers from 1 to 100\n\none_to_one_hundred &lt;- seq(1,100,1)\n\nWe can repeat things, using rep. Here’s making 10 5s, and 25 1s:\n\nrep(10,5)\n\n[1] 10 10 10 10 10\n\nrep(1,25)\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\nall_together_now &lt;- c(rep(10,5),rep(1,25)) \n\n\n\n\nLet’s work with the numbers 1 to 256. First, we’ll use the `sum()` function to add them up.\n\none_to_one_hundred &lt;- seq(1,100,1)\nsum(one_to_one_hundred)\n\n[1] 5050\n\n\n\n\n\nWe put 100 numbers into the variable one_to_one_hundred. We know how many numbers there are in there. How can we get R to tell us? We use length() for that.\n\nlength(one_to_one_hundred)\n\n[1] 100\n\n\n\n\n\n\n\nRemember the mean of some numbers is their sum, divided by the number of numbers. We can compute the mean like this:\n\nsum(one_to_one_hundred)/length(one_to_one_hundred)\n\n[1] 50.5\n\n\nOr, we could just use the mean() function like this:\n\nmean(one_to_one_hundred)\n\n[1] 50.5\n\n\n\n\n\nThe median is the number that lies exactly in the middle of a sorted list of numbers. If the list has an even number of elements, the median is calculated as the average of the two middle numbers. You can use the median() function to find it. For example, in a list of three numbers, the middle number is 2, so the median is 2.\n\nmedian(c(1,2,3))\n\n[1] 2\n\n\n\n\n\nR does not have a built-in function for calculating the mode. You will need to write one yourself. Here is an example of how to create a mode function and use it. Remember, the mode is the number that appears most frequently in a dataset. In the example below, 1 occurs the most often, so the mode is 1.\n\nmode &lt;- function(x) {\n  ux &lt;- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\nmode(c(1,1,1,1,1,1,1,2,3,4))\n\n[1] 1\n\n\n\n\n\n\nWe often want to understand how much the numbers vary. To describe this variability, we look at descriptive statistics such as range, variance, the standard deviation, and others.\nFirst, let’s remind ourselves what variation looks like (it refers to differences among numbers). We’ll sample 1000 numbers from a normal distribution with a mean of 101 and a standard deviation of 35. Then, we’ll create a histogram to visualize the variation around the mean of 10.\n\nsample_numbers &lt;- rnorm(1000,101,35)\nhist(sample_numbers)\n\n\n\n\n\n\n\n\n\n\nThe range is the minimum and maximum values in the set, we use the range function.\n\nrange(sample_numbers)\n\n[1] -20.99564 199.26425\n\n\n\n\n\nWe can find the sample variance using var().\n\nvar(sample_numbers)\n\n[1] 1355.992\n\n\n\n\n\nWe find the sample standard deviation us SD.\n\nsd(sample_numbers)\n\n[1] 36.8238\n\n\nRemember that the standard deviation is just the square root of the variance, see:\n\nsqrt(var(sample_numbers))\n\n[1] 36.8238\n\n\n\n\n\n\nsample_numbers &lt;- rnorm(1000,101,35)\n\nsum(sample_numbers)\n\n[1] 102476\n\nlength(sample_numbers)\n\n[1] 1000\n\nmean(sample_numbers)\n\n[1] 102.476\n\nmedian(sample_numbers)\n\n[1] 102.2365\n\nmode(sample_numbers)\n\n[1] 109.5741\n\nrange(sample_numbers)\n\n[1]  -5.618234 220.171208\n\nvar(sample_numbers)\n\n[1] 1237.785\n\nsd(sample_numbers)\n\n[1] 35.18217\n\n\n\n\n\n\nIn some instances, a single variable may contain a number of values, which can be analyzed using the aforementioned functions to obtain descriptive statistics. Conversely, in the majority of cases encountered in this course, a data frame comprising numerous numerical values representing different conditions will be employed. In such instances, it is necessary to identify descriptive statistics for each set of values within each condition.\nFortunately, the R programming language is highly adept at performing this task in a single operation. To illustrate this concept, consider the following example. A data frame containing 10 numbers for each condition will be created. There are 10 conditions, each labeled A, B, C, D, E, F, G, H, I, and J.\n\nscores &lt;- rnorm(100,10,5)\nconditions &lt;- rep(c(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"), each =10)\nmy_df &lt;- data.frame(conditions,scores)\n\nA review of the my_df data frame reveals that it contains 100 rows. Each row represents a distinct condition, with a label in the conditions column and 10 scores for that condition in the scores column. One might inquire as to the mean of the scores in each condition. In order to obtain the mean of the scores for each condition, one must find the mean of 10 scores.\nThe slow way to do it would be like this:\n\nmean(my_df[my_df$conditions==\"A\",]$scores)\n\n[1] 8.383671\n\nmean(my_df[my_df$conditions==\"B\",]$scores)\n\n[1] 9.801244\n\nmean(my_df[my_df$conditions==\"C\",]$scores)\n\n[1] 11.44105\n\n# and then keep going\n\nIt is evident that no individual or entity is willing to assume the responsibility of performing this task. It is therefore prudent to encapsulate this functionality, and R provides us with the necessary tools to automate this functionality.\n\n\nWe can easily do everything all at once using the group_by and summarise function from the dplyr package. Just watch\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmy_df %&gt;%\n  group_by(conditions) %&gt;%\n  summarise(means = mean(scores))\n\n# A tibble: 10 × 2\n   conditions means\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 A           8.38\n 2 B           9.80\n 3 C          11.4 \n 4 D           7.97\n 5 E           7.78\n 6 F          12.1 \n 7 G           9.83\n 8 H           9.98\n 9 I          12.8 \n10 J           9.42\n\n\nA few points require further consideration. Firstly, the printout of this was of an inferior quality. A solution to this issue is to create a new variable containing the results of the code and then use the knitr::kable function to print the variable in a more aesthetically pleasing manner when the document is compiled.\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\n\n\n\n\nA\n8.383671\n\n\nB\n9.801244\n\n\nC\n11.441048\n\n\nD\n7.974663\n\n\nE\n7.781818\n\n\nF\n12.135713\n\n\nG\n9.825402\n\n\nH\n9.977129\n\n\nI\n12.819841\n\n\nJ\n9.419859\n\n\n\n\n\n\n\n\nThe most advantageous aspect of the dplyr method is that it permits the addition of multiple functions, resulting in the generation of multiple summary statistics in a unified format. To illustrate this, consider the calculation of the standard deviation:\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores),\n                         sds = sd(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\nsds\n\n\n\n\nA\n8.383671\n4.628645\n\n\nB\n9.801244\n5.308608\n\n\nC\n11.441048\n3.989864\n\n\nD\n7.974663\n3.307205\n\n\nE\n7.781818\n4.259350\n\n\nF\n12.135713\n5.319706\n\n\nG\n9.825402\n5.487877\n\n\nH\n9.977129\n3.941479\n\n\nI\n12.819841\n3.605219\n\n\nJ\n9.419859\n3.559865\n\n\n\n\n\nFurthermore, the minimum and maximum values will be included.\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores),\n                         sds = sd(scores),\n                         min = min(scores),\n                         max = max(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\nsds\nmin\nmax\n\n\n\n\nA\n8.383671\n4.628645\n0.7328838\n13.89646\n\n\nB\n9.801244\n5.308608\n3.5712960\n19.72275\n\n\nC\n11.441048\n3.989864\n4.7661719\n17.85150\n\n\nD\n7.974663\n3.307205\n2.5534580\n15.31436\n\n\nE\n7.781818\n4.259350\n2.3406561\n14.87115\n\n\nF\n12.135713\n5.319706\n1.7331240\n19.69039\n\n\nG\n9.825402\n5.487877\n1.1443116\n18.16272\n\n\nH\n9.977129\n3.941479\n4.6518956\n14.60040\n\n\nI\n12.819841\n3.605219\n7.3310402\n18.92470\n\n\nJ\n9.419859\n3.559865\n3.6327248\n15.14616\n\n\n\n\n\n\n\n\n\nHaving established the methodology for obtaining descriptive statistics from R, we may now proceed to apply this methodology to a real data set. We will now proceed to inquire about the gapminder data.\n\nlibrary(gapminder)\ngapminder_df &lt;- gapminder\n\nNote: The code will only function properly if the gapminder package has been installed. It is imperative that the user is connected to the internet prior to commencing the installation process. To do so, navigate to the Packages tab, located in the bottom right panel, and select the option to install. Subsequently, a search for the gapminder package should be conducted, after which it should be selected and installed.\n\n\nCopy the code from the last part of descriptives using dplyr, then change the names like this:\n\nsummary_df &lt;- gapminder_df %&gt;%\n               group_by(continent) %&gt;%\n               summarise(means = mean(lifeExp),\n                         sds = sd(lifeExp),\n                         min = min(lifeExp),\n                         max = max(lifeExp))\n\nknitr::kable(summary_df)\n\n\n\n\ncontinent\nmeans\nsds\nmin\nmax\n\n\n\n\nAfrica\n48.86533\n9.150210\n23.599\n76.442\n\n\nAmericas\n64.65874\n9.345088\n37.579\n80.653\n\n\nAsia\n60.06490\n11.864532\n28.801\n82.603\n\n\nEurope\n71.90369\n5.433178\n43.585\n81.757\n\n\nOceania\n74.32621\n3.795611\n69.120\n81.235\n\n\n\n\n\n\n\n\n\nComplete the generalization exercise described in your R Markdown document for this lab.\n\nWhat is the mean, standard deviation, minimum and maximum life expectancy for all the gapminder data (across all the years and countries). Hint: do not use group_by\nWhat is the mean, standard deviation, minimum and maximum life expectancy for all of the continents in 2007, the most recent year in the dataset. Hint: add another pipe using filter(year==2007) %&gt;%\n\n\n\n\nComplete the writing assignment described in your R Markdown document for this lab. When you have finished everything. Knit the document and hand in your stuff (you can submit your .RMD file to blackboard if it does not knit.)\nYour writing assignment is to answer these questions in full sentences using simple plain langauge:\n\nDefine the mode.\nExplain what would need to happen in order for a set of numbers to have two modes\nDefine the median\nDefine the mean\nDefine the range\nWhen calculating the standard deviation, explain what the difference scores represent\nExplain why the difference scores are squared when calculating the standard deviation\nIf one set of numbers had a standard deviation of 5, and another had a standard deviation of 10, which set of numbers would have greater variance, explain why.\n\n\n\n\nNow let’s use a real dataset to calculate the same measures of central tendency and variability as in the previous example, but with the addition of a histogram to visualize the distribution and relate back to the descriptive statistics. Here is a link to the life expectancy dataset we used for our graphing tutorial. It is named life_expectancy.csv.\nSuppose we wanted to know about life expectancy around the world in 2018. This will include calculating descriptive statistics and graphing a histogram to examine the distribution of our data. R allows us to handle these tasks efficiently with a few lines of code.\n\n\n\nLoad the Data:\n\nFirst, ensure you have the dataset life_expectancy.csv in your working directory.\nLoad the data into R.\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load the data\nlife_expectancy &lt;- read.csv(\"data/life_expectancy.csv\")\nCalculate Descriptive Statistics:\n\nCalculate the measures of central tendency (mean, median, mode) and measures of variability (range, standard deviation, variance) for life expectancy in 2018.\n\n# Filter for the year 2018\nlife_2018 &lt;- life_expectancy %&gt;% filter(Year == 2018) %&gt;% select(life_expectancy)\n\n# Calculate descriptive statistics\n\n# Summarize the results\nCreate a Histogram:\n\nPlot a histogram to visualize the distribution of life expectancy in 2018, and overlay a normal curve.\n\n# Plot the histogram with a normal curve\nggplot(life_2018, aes(x = life_expectancy)) +\n  geom_histogram(aes(y = ..density..), binwidth = 2, fill = \"skyblue\", color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = mean_life, sd = sd_life), color = \"red\", size = 1) +\n  labs(title = \"Histogram of Life Expectancy in 2018\",\n       x = \"Life Expectancy\",\n       y = \"Density\") +\n  theme_minimal()\n\nThis process will produce a histogram displaying the distribution of life expectancy in 2018 with a superimposed normal curve for comparison.\n\n\n\nThink about what the mean, median, and mode indicate about the shape of the distribution. Is this confirmed when you look at the histogram? How does the shape of this distribution compare to the symmetrical normal distribution that is superimposed over it? The histogram helps visualize the skewness and spread of the data, providing a deeper understanding of the life expectancy distribution in 2018.\n\n\n\n\n\n\nUsing the life expectancy data set, produce a table of output showing the descriptive statistics (measures of central tendency and variability) for both years 1800 and 1934 (during the Great Depression).\nPlot histograms of life expectancy for both years. How are these distributions different? (Hint: Plot these on the same axes so that they are comparable).",
    "crumbs": [
      "Introduction",
      "R Basics"
    ]
  },
  {
    "objectID": "Chapter02_BasicProgramming.html",
    "href": "Chapter02_BasicProgramming.html",
    "title": "Basic programing",
    "section": "",
    "text": "This lecture has avoided the term “programming” due to its intimidating connotation. While advanced programming is a specialized skill, the basics are accessible and can achieve impressive results. This chapter introduces basic programming concepts in R, a language you’ve been using interactively so far.\nProgramming is essentially writing instructions for a computer in a language it can interpret, as a cooking recipe in a language like R. You’ve been entering commands at the prompt, but you can also write a program using R commands. This means you’re close to being able to program in R at a beginner’s level.\nComputer programs can take many forms, including scripts, which are of interest for everyday data analysis in R. Scripts involve writing all commands in a text file, which R can execute using the source() function.\nScripts are useful for several reasons. They allow you to save your work effectively, making it easier to correct mistakes without starting from scratch. They also let you leave notes for yourself, aiding recall of your analysis process. Finally, scripts make it easier to reuse or adapt your analyses for similar problems in the future.\nThe interactive style of entering commands one at a time has its uses, but also drawbacks. It’s challenging to save your work effectively, tedious to correct mistakes, and difficult to leave notes or reuse analyses. Scripts address these issues, making them a valuable tool for data analysis.",
    "crumbs": [
      "Introduction",
      "Basic programing"
    ]
  },
  {
    "objectID": "Chapter02_BasicProgramming.html#flow-control",
    "href": "Chapter02_BasicProgramming.html#flow-control",
    "title": "Basic programing",
    "section": "Flow control",
    "text": "Flow control\nIn scripting, R doesn’t necessarily start at the top of the file and run straight through to the end. Depending on how you write the script, you can have R repeat several commands or skip over different commands. This topic is referred to as flow control, and the first concept to discuss in this respect is the idea of a loop. A loop in R is a control flow statement that allows you to repeat a block of code multiple times. There are several types of loops in R, each serving different purposes and use cases. The most common types of loops in R are for loops and while loops.\nA loop in R is a control flow statement that allows you to repeat a block of code multiple times. There are several types of loops in R, each serving different purposes and use cases. The most common types of loops in R are for loops and while loops.\n\nfor Loop\nA for loop is used to iterate over a sequence (such as a vector, list, or any iterable object) and execute a block of code for each element in the sequence.\n\nSyntax:\n$ R\nfor (variable in sequence) {\n  # Code to be executed for each element\n}\n\n\nExample:\n\n# Print numbers from 1 to 5\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n\n\n\nwhile Loop\nA while loop repeatedly executes a block of code as long as a specified condition is TRUE.\n\nSyntax:\n$ R\nwhile (condition) {\n  # Code to be executed as long as the condition is TRUE\n}\n\n\nExample:\n\n# Print numbers from 1 to 5\ni &lt;- 1\nwhile (i &lt;= 5) {\n  print(i)\n  i &lt;- i + 1\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n\n\n\nrepeat Loop\nA repeat loop executes an infinite loop unless explicitly stopped using the break statement.\n\nSyntax:\n$ R\nrepeat {\n  # Code to be executed repeatedly\n  if (condition) {\n    break\n  }\n}\n\n\nExample:\n\n# Print numbers from 1 to 5\ni &lt;- 1\nrepeat {\n  print(i)\n  i &lt;- i + 1\n  if (i &gt; 5) {\n    break\n  }\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n\n\n\nBreaking Out of Loops\nYou can use the break statement to exit a loop prematurely, and the next statement to skip the current iteration and move to the next iteration of the loop.\n\nbreak Example:\n\nfor (i in 1:10) {\n  if (i == 6) {\n    break\n  }\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n\n\nnext Example:\n\nfor (i in 1:10) {\n  if (i %% 2 == 0) {\n    next\n  }\n  print(i)\n}\n\n[1] 1\n[1] 3\n[1] 5\n[1] 7\n[1] 9\n\n\n\n\n\nLoop Alternatives\nIn R, vectorized operations and the apply family of functions (lapply, sapply, apply, tapply, mapply) are often used as alternatives to loops for more efficient and concise code.\n\nExample using lapply:\n\n# Create a list of numbers from 1 to 5\nnumbers &lt;- list(1, 2, 3, 4, 5)\n\n# Apply a function to each element of the list\nsquared_numbers &lt;- lapply(numbers, function(x) x^2)\n\n# Print the squared numbers\nprint(squared_numbers)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 9\n\n[[4]]\n[1] 16\n\n[[5]]\n[1] 25\n\n\nLoops are powerful tools in R for repeating tasks and iterating over data structures. However, for performance and readability, vectorized operations and apply functions are often preferred.\nLet’s use a bioinformatics example. Suppose we have a vector of DNA sequences and we want to calculate the GC content of each sequence. Here’s the script:\n\n## --- bioexample.R\n#  author: Andres Chamorro\n#  date: Jun 26 2024\n\n# The DNA sequences\nsequences &lt;- c(\"ATGCGTA\", \"CGTACGT\", \"TACGTACG\")\n\n# Loop over the sequences\nfor (seq in sequences) {\n\n  # Calculate the GC content\n  gc_content &lt;- (sum(nchar(gsub(\"[AT]\", \"\", seq))) / nchar(seq)) * 100\n  \n  # Print the GC content\n  print(paste(\"The GC content of\", seq, \"is\", round(gc_content, 2), \"%\"))\n  \n}\n\n[1] \"The GC content of ATGCGTA is 42.86 %\"\n[1] \"The GC content of CGTACGT is 57.14 %\"\n[1] \"The GC content of TACGTACG is 50 %\"\n\n\nIn this script, the vector of possible values for the seq variable corresponds to the DNA sequences. The body of the loop calculates the GC content of each sequence and prints it. When we run this script, R starts at the top and creates a new variable called seq and assigns it a value of the first DNA sequence. It then moves down to the loop, and “notices” that there are more sequences in the vector. It then enters the body of the loop (inside the curly braces). The commands here instruct R to calculate the GC content of the sequence and print it. R then returns to the top of the loop, and rechecks if there are more sequences in the vector. If there are, then R goes on to execute all … well, you get the idea. This continues until all sequences in the vector have been processed. At this point, the loop stops, and R finally reaches the end of the script.\nConditional statements in R allow you to execute different pieces of code based on whether a condition is true or false. The most common conditional statements in R are if, else, and else if.\n\n\n\nConditional statements\nThe if statement allows you to execute a block of code if a condition is true.\n\nSyntax:\n$ R\nif (condition) {\n  # Code to execute if condition is true\n}\n\n\nExample:\n\nx &lt;- 5\n\nif (x &gt; 0) {\n  print(\"x is positive\")\n}\n\n[1] \"x is positive\"\n\n\n\n\nif-else Statement\nThe if-else statement allows you to execute one block of code if a condition is true and another block of code if the condition is false.\n\n\nSyntax:\n$ R\nif (condition) {\n  # Code to execute if condition is true\n} else {\n  # Code to execute if condition is false\n}\n\n\nExample:\n\nx &lt;- -3\n\nif (x &gt; 0) {\n  print(\"x is positive\")\n} else {\n  print(\"x is negative or zero\")\n}\n\n[1] \"x is negative or zero\"\n\n\nThe if-else statement allows you to check multiple conditions and execute different blocks of code based on which condition is true.\n\n\nExample:\n\nx &lt;- 0\n\nif (x &gt; 0) {\n  print(\"x is positive\")\n} else if (x &lt; 0) {\n  print(\"x is negative\")\n} else {\n  print(\"x is zero\")\n}\n\n[1] \"x is zero\"\n\n\nConditional statements are essential in R for decision-making and control flow, allowing you to execute different code paths based on specific conditions.",
    "crumbs": [
      "Introduction",
      "Basic programing"
    ]
  },
  {
    "objectID": "Chapter02_BasicProgramming.html#functions-in-r",
    "href": "Chapter02_BasicProgramming.html#functions-in-r",
    "title": "Basic programing",
    "section": "Functions in R",
    "text": "Functions in R\nA function in R is a block of code that performs a specific task, which can be reused and executed when called. Functions can take inputs (arguments), perform operations on those inputs, and return outputs.\n\nDefining Functions\n\nSyntax:\n$ R\nfunction_name &lt;- function(arg1, arg2, ...) {\n  # Code to execute\n  return(result)\n}\n\n\nExample:\n\n# Define a simple function to add two numbers\nadd_numbers &lt;- function(a, b) {\n  sum &lt;- a + b\n  return(sum)\n}\n\n# Call the function\nresult &lt;- add_numbers(3, 5)\nprint(result)  # Output: 8\n\n[1] 8\n\n\n\n\n\nCustom Functions\nFunctions in R are powerful tools that can be customized to perform a wide variety of tasks. In bioinformatics, they are particularly useful for tasks such as sequence analysis, gene expression normalization, and sequence alignment. By encapsulating code into functions, you can make your analysis more atomic, reusable, and easier to understand.\n\n1. DNA Sequence Analysis\n\nExample: Function to Count Nucleotides\nCounting nucleotides is a fundamental task in genomics. Understanding the composition of a DNA sequence can provide insights into genetic variations and functions.\n\n# Function to count nucleotides in a DNA sequence\ncount_nucleotides &lt;- function(dna_sequence) {\n  counts &lt;- table(strsplit(dna_sequence, \"\")[[1]])\n  return(counts)\n}\n\n# Test the function\ndna &lt;- \"ATGCTAGCTAGGCTA\"\nnucleotide_counts &lt;- count_nucleotides(dna)\nprint(nucleotide_counts)  # Output: A C G T \n\n\nA C G T \n4 3 4 4 \n\n                          #         4 4 3 4\n\n\n\n\n2. Protein Sequence Analysis\n\nExample: Function to Translate DNA to Protein\nTranslating DNA to protein is crucial for understanding gene expression and function. This function helps in converting nucleotide sequences into their corresponding amino acid sequences, aiding in protein analysis.\n\n# Load necessary library\n# To install package, enter in console\"\n# if (!require(\"BiocManager\", quietly = TRUE))\n#    install.packages(\"BiocManager\")\n# BiocManager::install(\"Biostrings\")\nlibrary(Biostrings)\n\nLoading required package: BiocGenerics\n\n\n\nAttaching package: 'BiocGenerics'\n\n\nThe following objects are masked from 'package:stats':\n\n    IQR, mad, sd, var, xtabs\n\n\nThe following objects are masked from 'package:base':\n\n    anyDuplicated, aperm, append, as.data.frame, basename, cbind,\n    colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find,\n    get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply,\n    match, mget, order, paste, pmax, pmax.int, pmin, pmin.int,\n    Position, rank, rbind, Reduce, rownames, sapply, setdiff, table,\n    tapply, union, unique, unsplit, which.max, which.min\n\n\nLoading required package: S4Vectors\n\n\nLoading required package: stats4\n\n\n\nAttaching package: 'S4Vectors'\n\n\nThe following object is masked from 'package:utils':\n\n    findMatches\n\n\nThe following objects are masked from 'package:base':\n\n    expand.grid, I, unname\n\n\nLoading required package: IRanges\n\n\nLoading required package: XVector\n\n\nLoading required package: GenomeInfoDb\n\n\n\nAttaching package: 'Biostrings'\n\n\nThe following object is masked from 'package:base':\n\n    strsplit\n\n# Function to translate DNA sequence to protein sequence\ntranslate_dna &lt;- function(dna_sequence) {\n  protein_sequence &lt;- sapply(seq(1, nchar(dna_sequence) - 2, by = 3), function(i) {\n    codon &lt;- substr(dna_sequence, i, i + 2)\n    return(GENETIC_CODE[[codon]])\n  })\n\n  return(paste(protein_sequence, collapse = \"\"))\n}\n\n# Test the function\ndna &lt;- \"ATGGTCTAACGTA\"\nprotein &lt;- translate_dna(dna)\nprint(protein)  # Output: \"MV*R\"\n\n[1] \"MV*R\"\n\n\n\n\n\n3. Sequence Alignment\n\nExample: Function to Perform Global Alignment\nSequence alignment is a core bioinformatics task used to find similarities between sequences, which can indicate functional, structural, or evolutionary relationships. The pairwiseAlignment function from the Biostrings package in Bioconductor provides a robust way to perform sequence alignments.\n\n# Load necessary library\n# To install package, enter in console\"\n# if (!require(\"BiocManager\", quietly = TRUE))\n#    install.packages(\"BiocManager\")\n# BiocManager::install(\"pwalign\")\nlibrary(pwalign)\n\n\nAttaching package: 'pwalign'\n\n\nThe following objects are masked from 'package:Biostrings':\n\n    aligned, alignedPattern, alignedSubject, compareStrings, deletion,\n    errorSubstitutionMatrices, indel, insertion, mismatchSummary,\n    mismatchTable, nedit, nindel, nucleotideSubstitutionMatrix,\n    pairwiseAlignment, PairwiseAlignments,\n    PairwiseAlignmentsSingleSubject, pid, qualitySubstitutionMatrices,\n    stringDist, unaligned, writePairwiseAlignments\n\n# Function to perform global alignment between two sequences\nglobal_alignment &lt;- function(seq1, seq2) {\n  alignment &lt;- pairwiseAlignment(seq1, seq2, type = \"global\")\n  return(alignment)\n}\n\n# Test the function\nseq1 &lt;- DNAString(\"ATGCTAGCTAG\")\nseq2 &lt;- DNAString(\"ATGCTAGGCTA\")\nalignment_result &lt;- global_alignment(seq1, seq2)\nprint(alignment_result)\n\nGlobal PairwiseAlignmentsSingleSubject (1 of 1)\npattern: ATGCTAG-CTAG\nsubject: ATGCTAGGCTA-\nscore: -8.182438 \n\n\n\n\n\n4. Gene Expression Analysis\n\nExample: Function to Normalize Gene Expression Data\nNormalizing gene expression data is essential for comparing expression levels across different genes and samples. Log transformation is a common normalization method to reduce skewness and stabilize variance.\n\n# Function to normalize gene expression data using log transformation\nnormalize_expression &lt;- function(expression_data) {\n  normalized_data &lt;- log2(expression_data + 1)\n  return(normalized_data)\n}\n\n# Test the function\nexpression_data &lt;- c(100, 200, 300, 400, 500)\nnormalized_data &lt;- normalize_expression(expression_data)\nprint(normalized_data)  # Output: 6.658211 7.643856 8.228819 8.643856 8.965784\n\n[1] 6.658211 7.651052 8.233620 8.647458 8.968667",
    "crumbs": [
      "Introduction",
      "Basic programing"
    ]
  },
  {
    "objectID": "Chapter02_BasicProgramming.html#exercises",
    "href": "Chapter02_BasicProgramming.html#exercises",
    "title": "Basic programing",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1: Analyzing Gene Expression Data\n\nObjective:\nWrite a function in R to calculate basic descriptive statistics (mean, median, standard deviation) for a given gene expression dataset.\n\n\nInstructions:\n\nCreate a random vector gene_expression, of size 100 with uniform distribution.\nWrite a function describe_expression that takes a numeric vector as input and returns a list with the mean, median, and standard deviation of the input data.\n\n\n\n\nExercise 2: Descriptive Statistics of Protein Abundances\n\nObjective:\nAnalyze the protein abundance data from different samples and calculate descriptive statistics for each sample.\n\n\nInstructions:\n\nCreate a data frame protein_data with the following values:\n\nSample1: c(0.5, 0.8, 1.0, 1.2, 0.9)\nSample2: c(1.5, 1.7, 1.6, 1.8, 1.9)\nSample3: c(2.1, 2.3, 2.2, 2.5, 2.4)\n\nWrite a function summary_statistics that calculates the mean, median, and standard deviation for each sample in the data frame.\nTest the function with the protein_data data frame.\n\n\n\nTemplate:\n\n# Create the data frame with protein abundance data\nprotein_data &lt;- data.frame(\n  dummy = double()\n  # Code here\n)\n\n# Define the function to calculate descriptive statistics for each numeric column in a data frame\nsummary_statistics &lt;- function(data) {\n  # Check if input is a data frame\n  if (!is.data.frame(data)) {\n    stop(\"Input must be a data frame\")\n  }\n  \n  # Initialize an empty list to store statistics for each column\n  stats_list &lt;- list()\n  \n  # Iterate over each column in the data frame\n  for (colname in names(data)) {\n    # Check if the column is numeric\n    if (is.numeric(data[[colname]])) {\n      # Compute descriptive statistics on column colname\n      mean_value = 0.0 # Dummy value\n      median_value = 0.0 # Dummy value\n      sd_value = 0.0 # Dummy value\n      # Example\n      min_value &lt;- min(data[[colname]], na.rm = TRUE)\n      max_value &lt;- max(data[[colname]], na.rm = TRUE)\n      \n      # Create a named vector of statistics\n      stats &lt;- c(mean = mean_value, median = median_value, sd = sd_value, min = min_value, max = max_value)\n      # Add the statistics to the list with the column name as the key\n      stats_list[[colname]] &lt;- stats\n    }\n  }\n  # Convert the list of statistics to a data frame\n  stats_df &lt;- do.call(rbind, stats_list)\n  # Return the data frame of descriptive statistics\n  return(as.data.frame(stats_df))\n}\n\n# Test the function\nprotein_stats &lt;- summary_statistics(protein_data)\n\nWarning in min(data[[colname]], na.rm = TRUE): no non-missing arguments to min;\nreturning Inf\n\n\nWarning in max(data[[colname]], na.rm = TRUE): no non-missing arguments to max;\nreturning -Inf\n\nknitr::kable(protein_stats)\n\n\n\n\n\nmean\nmedian\nsd\nmin\nmax\n\n\n\n\ndummy\n0\n0\n0\nInf\n-Inf\n\n\n\n\n\n\n\nExpected Output:\n\n\n\n\nmean\nmedian\nsd\nmin\nmax\n\n\n\n\nSample1\n0.88\n0.9\n0.2588436\n0.5\n1.2\n\n\nSample2\n1.70\n1.7\n0.1581139\n1.5\n1.9\n\n\nSample3\n2.30\n2.3\n0.1581139\n2.1\n2.5",
    "crumbs": [
      "Introduction",
      "Basic programing"
    ]
  }
]