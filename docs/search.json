[
  {
    "objectID": "Chapter01_Introduction.html",
    "href": "Chapter01_Introduction.html",
    "title": "R Basics",
    "section": "",
    "text": "This section covers everything you need to perform statistical analysis using R(2024). Similar to other programming languages, R has a base package and an Integrated Development Environment (IDE). The base package allows you to run R code on your computer, while R Studio is an IDE specifically designed for developing R programs and packages.\n\n\nThe R base package can be downloaded from the official R website. Once on the website, select the precompiled binary for your operating system, download the file, and install it. To verify that R has been successfully installed, open your command prompt (cmd) or terminal and type R to start the R console. To exit the R console, type q().\n$ R\n\nR version 4.4.0 (2024-04-24) -- \"Puppy Cup\"\nCopyright (C) 2024 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n&gt; q()\n\n\n\nRStudio is an essential tool for anyone working with the R programming language. It serves as an integrated development environment (IDE) that makes working with R more efficient and user-friendly. Here’s what you need to know:\n\n\nRStudio is a flexible, multifunctional open-source IDE that serves as a graphical front-end for working with R (version 3.0.1 or higher). Additionally, it supports other programming languages like Python and SQL. Key features of RStudio include a user-friendly interface, the ability to write and save reusable scripts, and easy access to imported data and created objects such as variables and functions. It provides exhaustive help on any object, offers code autocompletion, and facilitates project organization and collaboration. Users can preview plots, switch between the terminal and console, and track their operational history, making it an indispensable tool for data analysis and programming.\n\n\n\nTo install RStudio, begin by visiting the official RStudio website. Scroll down to locate the download buttons for RStudio Desktop. Select the precompiled binary appropriate for your operating system, download the file, and install it.\n\n\n\n\n\nDataCamp’s RStudio Tutorial: A comprehensive guide for beginners.\nDataquest’s Getting Started with R and RStudio: Learn key features and start programming in R.\nGitHub Pages: Introduction to RStudio: Fundamentals of RStudio for scientific projects.\nIntroduction to R and RStudio (GitBook): Best practices for organizing code using RStudio.\nRStudio for the Total Beginner: An accessible introduction to RStudio for the total beginner.\n\n\n\n\nLearning Statistics with R\nStatistical Methods in Medical Research\n\n\n\n\n\nDescriptive statistics is a branch of statistics that focuses on summarizing and describing the features of a dataset. It provides simple summaries about the sample and the measures, offering a way to present data in a meaningful and understandable form. The origins of descriptive statistics date back to the early days of statistical science, where it served as the foundational method for analyzing data.\nHistory:\nThe roots of descriptive statistics can be traced back to ancient civilizations, such as the Babylonians and Egyptians, who used basic statistical methods to manage agricultural data, censuses, and astronomical information. However, the formal development of descriptive statistics began in the 17th and 18th centuries. John Graunt, an English demographer, is often credited with laying the groundwork for statistical analysis through his work on mortality rates in the 1660s. His pioneering efforts in collecting and analyzing data led to the birth of modern statistics.\nIn the 18th century, the field was further advanced by the work of mathematicians like Pierre-Simon Laplace and Carl Friedrich Gauss, who developed key statistical concepts and methods. The 19th and 20th centuries saw the emergence of more sophisticated statistical techniques and the formalization of the discipline. Descriptive statistics evolved to include a variety of measures and graphical representations that remain fundamental to data analysis today.\nExamples:\n\nMeasures of Central Tendency:\n\nMean: The arithmetic average of a set of numbers. For example, in a dataset of test scores (80, 85, 90, 75, 95), the mean score is calculated as (80 + 85 + 90 + 75 + 95) / 5 = 85.\nMedian: The middle value in a dataset when the numbers are arranged in ascending order. In the test scores example, the median score is 85.\nMode: The most frequently occurring value in a dataset. If a dataset of test scores is (80, 85, 85, 90, 95), the mode is 85.\n\nMeasures of Dispersion:\n\nRange: The difference between the highest and lowest values in a dataset. For test scores (75, 80, 85, 90, 95), the range is 95 - 75 = 20.\nVariance: A measure of the spread of a dataset. It is the average of the squared differences from the mean. For the test scores, the variance can be calculated by finding the mean, subtracting each score from the mean, squaring the result, and then averaging those squared differences.\nStandard Deviation: The square root of the variance, representing the average amount each value in the dataset differs from the mean. It provides insight into the dataset’s overall variability.\n\nGraphical Representations:\n\nHistograms: Bar graphs that represent the frequency distribution of a dataset. They help in visualizing the shape and spread of data.\nBox Plots: Graphical representations that show the distribution of a dataset based on a five-number summary: minimum, first quartile, median, third quartile, and maximum. Box plots highlight the central tendency and variability, as well as potential outliers.\nPie Charts: Circular charts divided into sectors representing proportions of the whole. They are useful for displaying categorical data and comparing parts of a whole.\n\n\nDescriptive statistics is essential in various fields, including economics, psychology, and social sciences, where it aids in making data-driven decisions. By providing a clear summary of data through measures of central tendency, dispersion, and graphical representations, descriptive statistics helps researchers and analysts interpret and communicate their findings effectively.\n\n\nTo perform descriptive statistics, we need to assign some numbers to a variable. This can be done using the `c()` function, which stands for combine.\n\nmy_numbers &lt;- c(1,2,3,4)\n\nThere a few other handy ways to make numbers. We can use seq() to make a sequence. Here’s making the numbers from 1 to 100\n\none_to_one_hundred &lt;- seq(1,100,1)\n\nWe can repeat things, using rep. Here’s making 10 5s, and 25 1s:\n\nrep(10,5)\n\n[1] 10 10 10 10 10\n\nrep(1,25)\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\nall_together_now &lt;- c(rep(10,5),rep(1,25)) \n\n\n\n\nLet’s work with the numbers 1 to 256. First, we’ll use the `sum()` function to add them up.\n\none_to_one_hundred &lt;- seq(1,100,1)\nsum(one_to_one_hundred)\n\n[1] 5050\n\n\n\n\n\nWe put 100 numbers into the variable one_to_one_hundred. We know how many numbers there are in there. How can we get R to tell us? We use length() for that.\n\nlength(one_to_one_hundred)\n\n[1] 100\n\n\n\n\n\n\n\nRemember the mean of some numbers is their sum, divided by the number of numbers. We can compute the mean like this:\n\nsum(one_to_one_hundred)/length(one_to_one_hundred)\n\n[1] 50.5\n\n\nOr, we could just use the mean() function like this:\n\nmean(one_to_one_hundred)\n\n[1] 50.5\n\n\n\n\n\nThe median is the number that lies exactly in the middle of a sorted list of numbers. If the list has an even number of elements, the median is calculated as the average of the two middle numbers. You can use the median() function to find it. For example, in a list of three numbers, the middle number is 2, so the median is 2.\n\nmedian(c(1,2,3))\n\n[1] 2\n\n\n\n\n\nR does not have a built-in function for calculating the mode. You will need to write one yourself. Here is an example of how to create a mode function and use it. Remember, the mode is the number that appears most frequently in a dataset. In the example below, 1 occurs the most often, so the mode is 1.\n\nmode &lt;- function(x) {\n  ux &lt;- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\nmode(c(1,1,1,1,1,1,1,2,3,4))\n\n[1] 1\n\n\n\n\n\n\nWe often want to understand how much the numbers vary. To describe this variability, we look at descriptive statistics such as range, variance, the standard deviation, and others.\nFirst, let’s remind ourselves what variation looks like (it refers to differences among numbers). We’ll sample 1000 numbers from a normal distribution with a mean of 101 and a standard deviation of 35. Then, we’ll create a histogram to visualize the variation around the mean of 10.\n\nsample_numbers &lt;- rnorm(1000,101,35)\nhist(sample_numbers)\n\n\n\n\n\n\n\n\n\n\nThe range is the minimum and maximum values in the set, we use the range function.\n\nrange(sample_numbers)\n\n[1] -19.95832 210.94027\n\n\n\n\n\nWe can find the sample variance using var().\n\nvar(sample_numbers)\n\n[1] 1231.083\n\n\n\n\n\nWe find the sample standard deviation us SD.\n\nsd(sample_numbers)\n\n[1] 35.08679\n\n\nRemember that the standard deviation is just the square root of the variance, see:\n\nsqrt(var(sample_numbers))\n\n[1] 35.08679\n\n\n\n\n\n\nsample_numbers &lt;- rnorm(1000,101,35)\n\nsum(sample_numbers)\n\n[1] 100149.8\n\nlength(sample_numbers)\n\n[1] 1000\n\nmean(sample_numbers)\n\n[1] 100.1498\n\nmedian(sample_numbers)\n\n[1] 98.73452\n\nmode(sample_numbers)\n\n[1] 68.33856\n\nrange(sample_numbers)\n\n[1]   5.996308 243.420367\n\nvar(sample_numbers)\n\n[1] 1123.757\n\nsd(sample_numbers)\n\n[1] 33.52248\n\n\n\n\n\n\nIn some instances, a single variable may contain a number of values, which can be analyzed using the aforementioned functions to obtain descriptive statistics. Conversely, in the majority of cases encountered in this course, a data frame comprising numerous numerical values representing different conditions will be employed. In such instances, it is necessary to identify descriptive statistics for each set of values within each condition.\nFortunately, the R programming language is highly adept at performing this task in a single operation. To illustrate this concept, consider the following example. A data frame containing 10 numbers for each condition will be created. There are 10 conditions, each labeled A, B, C, D, E, F, G, H, I, and J.\n\nscores &lt;- rnorm(100,10,5)\nconditions &lt;- rep(c(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"), each =10)\nmy_df &lt;- data.frame(conditions,scores)\n\nA review of the my_df data frame reveals that it contains 100 rows. Each row represents a distinct condition, with a label in the conditions column and 10 scores for that condition in the scores column. One might inquire as to the mean of the scores in each condition. In order to obtain the mean of the scores for each condition, one must find the mean of 10 scores.\nThe slow way to do it would be like this:\n\nmean(my_df[my_df$conditions==\"A\",]$scores)\n\n[1] 10.58511\n\nmean(my_df[my_df$conditions==\"B\",]$scores)\n\n[1] 8.018306\n\nmean(my_df[my_df$conditions==\"C\",]$scores)\n\n[1] 10.29478\n\n# and then keep going\n\nIt is evident that no individual or entity is willing to assume the responsibility of performing this task. It is therefore prudent to encapsulate this functionality, and R provides us with the necessary tools to automate this functionality.\n\n\nWe can easily do everything all at once using the group_by and summarise function from the dplyr package. Just watch\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmy_df %&gt;%\n  group_by(conditions) %&gt;%\n  summarise(means = mean(scores))\n\n# A tibble: 10 × 2\n   conditions means\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 A          10.6 \n 2 B           8.02\n 3 C          10.3 \n 4 D           8.69\n 5 E           9.51\n 6 F          11.1 \n 7 G           9.51\n 8 H           9.57\n 9 I          11.3 \n10 J          12.0 \n\n\nA few points require further consideration. Firstly, the printout of this was of an inferior quality. A solution to this issue is to create a new variable containing the results of the code and then use the knitr::kable function to print the variable in a more aesthetically pleasing manner when the document is compiled.\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\n\n\n\n\nA\n10.585114\n\n\nB\n8.018306\n\n\nC\n10.294783\n\n\nD\n8.687497\n\n\nE\n9.506123\n\n\nF\n11.071491\n\n\nG\n9.512394\n\n\nH\n9.571136\n\n\nI\n11.284107\n\n\nJ\n12.012939\n\n\n\n\n\n\n\n\nThe most advantageous aspect of the dplyr method is that it permits the addition of multiple functions, resulting in the generation of multiple summary statistics in a unified format. To illustrate this, consider the calculation of the standard deviation:\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores),\n                         sds = sd(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\nsds\n\n\n\n\nA\n10.585114\n5.679876\n\n\nB\n8.018306\n4.137335\n\n\nC\n10.294783\n5.358272\n\n\nD\n8.687497\n4.638121\n\n\nE\n9.506123\n3.122304\n\n\nF\n11.071491\n5.047547\n\n\nG\n9.512394\n4.854704\n\n\nH\n9.571136\n6.591424\n\n\nI\n11.284107\n5.762363\n\n\nJ\n12.012939\n5.145721\n\n\n\n\n\nFurthermore, the minimum and maximum values will be included.\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores),\n                         sds = sd(scores),\n                         min = min(scores),\n                         max = max(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\nsds\nmin\nmax\n\n\n\n\nA\n10.585114\n5.679876\n3.6182982\n20.44245\n\n\nB\n8.018306\n4.137335\n0.4974302\n12.28050\n\n\nC\n10.294783\n5.358272\n2.5335906\n15.91243\n\n\nD\n8.687497\n4.638121\n0.0110298\n15.25871\n\n\nE\n9.506123\n3.122304\n5.3783867\n15.37293\n\n\nF\n11.071491\n5.047547\n0.1306032\n18.75173\n\n\nG\n9.512394\n4.854704\n3.1293046\n17.04708\n\n\nH\n9.571136\n6.591424\n-1.0027310\n19.54346\n\n\nI\n11.284107\n5.762363\n3.4570481\n18.97414\n\n\nJ\n12.012939\n5.145721\n5.6354111\n20.06696\n\n\n\n\n\n\n\n\n\nHaving established the methodology for obtaining descriptive statistics from R, we may now proceed to apply this methodology to a real data set. We will now proceed to inquire about the gapminder data.\n\nlibrary(gapminder)\ngapminder_df &lt;- gapminder\n\nNote: The code will only function properly if the gapminder package has been installed. It is imperative that the user is connected to the internet prior to commencing the installation process. To do so, navigate to the Packages tab, located in the bottom right panel, and select the option to install. Subsequently, a search for the gapminder package should be conducted, after which it should be selected and installed.\n\n\nCopy the code from the last part of descriptives using dplyr, then change the names like this:\n\nsummary_df &lt;- gapminder_df %&gt;%\n               group_by(continent) %&gt;%\n               summarise(means = mean(lifeExp),\n                         sds = sd(lifeExp),\n                         min = min(lifeExp),\n                         max = max(lifeExp))\n\nknitr::kable(summary_df)\n\n\n\n\ncontinent\nmeans\nsds\nmin\nmax\n\n\n\n\nAfrica\n48.86533\n9.150210\n23.599\n76.442\n\n\nAmericas\n64.65874\n9.345088\n37.579\n80.653\n\n\nAsia\n60.06490\n11.864532\n28.801\n82.603\n\n\nEurope\n71.90369\n5.433178\n43.585\n81.757\n\n\nOceania\n74.32621\n3.795611\n69.120\n81.235\n\n\n\n\n\n\n\n\n\nComplete the generalization exercise described in your R Markdown document for this lab.\n\nWhat is the mean, standard deviation, minimum and maximum life expectancy for all the gapminder data (across all the years and countries). Hint: do not use group_by\nWhat is the mean, standard deviation, minimum and maximum life expectancy for all of the continents in 2007, the most recent year in the dataset. Hint: add another pipe using filter(year==2007) %&gt;%\n\n\n\n\nComplete the writing assignment described in your R Markdown document for this lab. When you have finished everything. Knit the document and hand in your stuff (you can submit your .RMD file to blackboard if it does not knit.)\nYour writing assignment is to answer these questions in full sentences using simple plain langauge:\n\nDefine the mode.\nExplain what would need to happen in order for a set of numbers to have two modes\nDefine the median\nDefine the mean\nDefine the range\nWhen calculating the standard deviation, explain what the difference scores represent\nExplain why the difference scores are squared when calculating the standard deviation\nIf one set of numbers had a standard deviation of 5, and another had a standard deviation of 10, which set of numbers would have greater variance, explain why.\n\n\n\n\nNow let’s use a real dataset to calculate the same measures of central tendency and variability as in the previous example, but with the addition of a histogram to visualize the distribution and relate back to the descriptive statistics. Here is a link to the life expectancy dataset we used for our graphing tutorial. It is named life_expectancy.csv.\nSuppose we wanted to know about life expectancy around the world in 2018. This will include calculating descriptive statistics and graphing a histogram to examine the distribution of our data. R allows us to handle these tasks efficiently with a few lines of code.\n\n\n\nLoad the Data:\n\nFirst, ensure you have the dataset life_expectancy.csv in your working directory.\nLoad the data into R.\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load the data\nlife_expectancy &lt;- read.csv(\"data/life_expectancy.csv\")\nCalculate Descriptive Statistics:\n\nCalculate the measures of central tendency (mean, median, mode) and measures of variability (range, standard deviation, variance) for life expectancy in 2018.\n\n# Filter for the year 2018\nlife_2018 &lt;- life_expectancy %&gt;% filter(Year == 2018) %&gt;% select(life_expectancy)\n\n# Calculate descriptive statistics\n\n# Summarize the results\nCreate a Histogram:\n\nPlot a histogram to visualize the distribution of life expectancy in 2018, and overlay a normal curve.\n\n# Plot the histogram with a normal curve\nggplot(life_2018, aes(x = life_expectancy)) +\n  geom_histogram(aes(y = ..density..), binwidth = 2, fill = \"skyblue\", color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = mean_life, sd = sd_life), color = \"red\", size = 1) +\n  labs(title = \"Histogram of Life Expectancy in 2018\",\n       x = \"Life Expectancy\",\n       y = \"Density\") +\n  theme_minimal()\n\nThis process will produce a histogram displaying the distribution of life expectancy in 2018 with a superimposed normal curve for comparison.\n\n\n\nThink about what the mean, median, and mode indicate about the shape of the distribution. Is this confirmed when you look at the histogram? How does the shape of this distribution compare to the symmetrical normal distribution that is superimposed over it? The histogram helps visualize the skewness and spread of the data, providing a deeper understanding of the life expectancy distribution in 2018.\n\n\n\n\n\n\nUsing the life expectancy data set, produce a table of output showing the descriptive statistics (measures of central tendency and variability) for both years 1800 and 1934 (during the Great Depression).\nPlot histograms of life expectancy for both years. How are these distributions different? (Hint: Plot these on the same axes so that they are comparable)."
  },
  {
    "objectID": "Chapter01_Introduction.html#installing",
    "href": "Chapter01_Introduction.html#installing",
    "title": "R Basics",
    "section": "",
    "text": "The R base package can be downloaded from the official R website. Once on the website, select the precompiled binary for your operating system, download the file, and install it. To verify that R has been successfully installed, open your command prompt (cmd) or terminal and type R to start the R console. To exit the R console, type q().\n$ R\n\nR version 4.4.0 (2024-04-24) -- \"Puppy Cup\"\nCopyright (C) 2024 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n&gt; q()"
  },
  {
    "objectID": "Chapter01_Introduction.html#introduction-to-rstudio",
    "href": "Chapter01_Introduction.html#introduction-to-rstudio",
    "title": "R Basics",
    "section": "",
    "text": "RStudio is an essential tool for anyone working with the R programming language. It serves as an integrated development environment (IDE) that makes working with R more efficient and user-friendly. Here’s what you need to know:\n\n\nRStudio is a flexible, multifunctional open-source IDE that serves as a graphical front-end for working with R (version 3.0.1 or higher). Additionally, it supports other programming languages like Python and SQL. Key features of RStudio include a user-friendly interface, the ability to write and save reusable scripts, and easy access to imported data and created objects such as variables and functions. It provides exhaustive help on any object, offers code autocompletion, and facilitates project organization and collaboration. Users can preview plots, switch between the terminal and console, and track their operational history, making it an indispensable tool for data analysis and programming.\n\n\n\nTo install RStudio, begin by visiting the official RStudio website. Scroll down to locate the download buttons for RStudio Desktop. Select the precompiled binary appropriate for your operating system, download the file, and install it."
  },
  {
    "objectID": "Chapter01_Introduction.html#additional-resources",
    "href": "Chapter01_Introduction.html#additional-resources",
    "title": "R Basics",
    "section": "",
    "text": "DataCamp’s RStudio Tutorial: A comprehensive guide for beginners.\nDataquest’s Getting Started with R and RStudio: Learn key features and start programming in R.\nGitHub Pages: Introduction to RStudio: Fundamentals of RStudio for scientific projects.\nIntroduction to R and RStudio (GitBook): Best practices for organizing code using RStudio.\nRStudio for the Total Beginner: An accessible introduction to RStudio for the total beginner.\n\n\n\n\nLearning Statistics with R\nStatistical Methods in Medical Research"
  },
  {
    "objectID": "Chapter01_Introduction.html#descriptive-statistics",
    "href": "Chapter01_Introduction.html#descriptive-statistics",
    "title": "R Basics",
    "section": "",
    "text": "Descriptive statistics is a branch of statistics that focuses on summarizing and describing the features of a dataset. It provides simple summaries about the sample and the measures, offering a way to present data in a meaningful and understandable form. The origins of descriptive statistics date back to the early days of statistical science, where it served as the foundational method for analyzing data.\nHistory:\nThe roots of descriptive statistics can be traced back to ancient civilizations, such as the Babylonians and Egyptians, who used basic statistical methods to manage agricultural data, censuses, and astronomical information. However, the formal development of descriptive statistics began in the 17th and 18th centuries. John Graunt, an English demographer, is often credited with laying the groundwork for statistical analysis through his work on mortality rates in the 1660s. His pioneering efforts in collecting and analyzing data led to the birth of modern statistics.\nIn the 18th century, the field was further advanced by the work of mathematicians like Pierre-Simon Laplace and Carl Friedrich Gauss, who developed key statistical concepts and methods. The 19th and 20th centuries saw the emergence of more sophisticated statistical techniques and the formalization of the discipline. Descriptive statistics evolved to include a variety of measures and graphical representations that remain fundamental to data analysis today.\nExamples:\n\nMeasures of Central Tendency:\n\nMean: The arithmetic average of a set of numbers. For example, in a dataset of test scores (80, 85, 90, 75, 95), the mean score is calculated as (80 + 85 + 90 + 75 + 95) / 5 = 85.\nMedian: The middle value in a dataset when the numbers are arranged in ascending order. In the test scores example, the median score is 85.\nMode: The most frequently occurring value in a dataset. If a dataset of test scores is (80, 85, 85, 90, 95), the mode is 85.\n\nMeasures of Dispersion:\n\nRange: The difference between the highest and lowest values in a dataset. For test scores (75, 80, 85, 90, 95), the range is 95 - 75 = 20.\nVariance: A measure of the spread of a dataset. It is the average of the squared differences from the mean. For the test scores, the variance can be calculated by finding the mean, subtracting each score from the mean, squaring the result, and then averaging those squared differences.\nStandard Deviation: The square root of the variance, representing the average amount each value in the dataset differs from the mean. It provides insight into the dataset’s overall variability.\n\nGraphical Representations:\n\nHistograms: Bar graphs that represent the frequency distribution of a dataset. They help in visualizing the shape and spread of data.\nBox Plots: Graphical representations that show the distribution of a dataset based on a five-number summary: minimum, first quartile, median, third quartile, and maximum. Box plots highlight the central tendency and variability, as well as potential outliers.\nPie Charts: Circular charts divided into sectors representing proportions of the whole. They are useful for displaying categorical data and comparing parts of a whole.\n\n\nDescriptive statistics is essential in various fields, including economics, psychology, and social sciences, where it aids in making data-driven decisions. By providing a clear summary of data through measures of central tendency, dispersion, and graphical representations, descriptive statistics helps researchers and analysts interpret and communicate their findings effectively.\n\n\nTo perform descriptive statistics, we need to assign some numbers to a variable. This can be done using the `c()` function, which stands for combine.\n\nmy_numbers &lt;- c(1,2,3,4)\n\nThere a few other handy ways to make numbers. We can use seq() to make a sequence. Here’s making the numbers from 1 to 100\n\none_to_one_hundred &lt;- seq(1,100,1)\n\nWe can repeat things, using rep. Here’s making 10 5s, and 25 1s:\n\nrep(10,5)\n\n[1] 10 10 10 10 10\n\nrep(1,25)\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\nall_together_now &lt;- c(rep(10,5),rep(1,25)) \n\n\n\n\nLet’s work with the numbers 1 to 256. First, we’ll use the `sum()` function to add them up.\n\none_to_one_hundred &lt;- seq(1,100,1)\nsum(one_to_one_hundred)\n\n[1] 5050\n\n\n\n\n\nWe put 100 numbers into the variable one_to_one_hundred. We know how many numbers there are in there. How can we get R to tell us? We use length() for that.\n\nlength(one_to_one_hundred)\n\n[1] 100\n\n\n\n\n\n\n\nRemember the mean of some numbers is their sum, divided by the number of numbers. We can compute the mean like this:\n\nsum(one_to_one_hundred)/length(one_to_one_hundred)\n\n[1] 50.5\n\n\nOr, we could just use the mean() function like this:\n\nmean(one_to_one_hundred)\n\n[1] 50.5\n\n\n\n\n\nThe median is the number that lies exactly in the middle of a sorted list of numbers. If the list has an even number of elements, the median is calculated as the average of the two middle numbers. You can use the median() function to find it. For example, in a list of three numbers, the middle number is 2, so the median is 2.\n\nmedian(c(1,2,3))\n\n[1] 2\n\n\n\n\n\nR does not have a built-in function for calculating the mode. You will need to write one yourself. Here is an example of how to create a mode function and use it. Remember, the mode is the number that appears most frequently in a dataset. In the example below, 1 occurs the most often, so the mode is 1.\n\nmode &lt;- function(x) {\n  ux &lt;- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\nmode(c(1,1,1,1,1,1,1,2,3,4))\n\n[1] 1\n\n\n\n\n\n\nWe often want to understand how much the numbers vary. To describe this variability, we look at descriptive statistics such as range, variance, the standard deviation, and others.\nFirst, let’s remind ourselves what variation looks like (it refers to differences among numbers). We’ll sample 1000 numbers from a normal distribution with a mean of 101 and a standard deviation of 35. Then, we’ll create a histogram to visualize the variation around the mean of 10.\n\nsample_numbers &lt;- rnorm(1000,101,35)\nhist(sample_numbers)\n\n\n\n\n\n\n\n\n\n\nThe range is the minimum and maximum values in the set, we use the range function.\n\nrange(sample_numbers)\n\n[1] -19.95832 210.94027\n\n\n\n\n\nWe can find the sample variance using var().\n\nvar(sample_numbers)\n\n[1] 1231.083\n\n\n\n\n\nWe find the sample standard deviation us SD.\n\nsd(sample_numbers)\n\n[1] 35.08679\n\n\nRemember that the standard deviation is just the square root of the variance, see:\n\nsqrt(var(sample_numbers))\n\n[1] 35.08679\n\n\n\n\n\n\nsample_numbers &lt;- rnorm(1000,101,35)\n\nsum(sample_numbers)\n\n[1] 100149.8\n\nlength(sample_numbers)\n\n[1] 1000\n\nmean(sample_numbers)\n\n[1] 100.1498\n\nmedian(sample_numbers)\n\n[1] 98.73452\n\nmode(sample_numbers)\n\n[1] 68.33856\n\nrange(sample_numbers)\n\n[1]   5.996308 243.420367\n\nvar(sample_numbers)\n\n[1] 1123.757\n\nsd(sample_numbers)\n\n[1] 33.52248\n\n\n\n\n\n\nIn some instances, a single variable may contain a number of values, which can be analyzed using the aforementioned functions to obtain descriptive statistics. Conversely, in the majority of cases encountered in this course, a data frame comprising numerous numerical values representing different conditions will be employed. In such instances, it is necessary to identify descriptive statistics for each set of values within each condition.\nFortunately, the R programming language is highly adept at performing this task in a single operation. To illustrate this concept, consider the following example. A data frame containing 10 numbers for each condition will be created. There are 10 conditions, each labeled A, B, C, D, E, F, G, H, I, and J.\n\nscores &lt;- rnorm(100,10,5)\nconditions &lt;- rep(c(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"), each =10)\nmy_df &lt;- data.frame(conditions,scores)\n\nA review of the my_df data frame reveals that it contains 100 rows. Each row represents a distinct condition, with a label in the conditions column and 10 scores for that condition in the scores column. One might inquire as to the mean of the scores in each condition. In order to obtain the mean of the scores for each condition, one must find the mean of 10 scores.\nThe slow way to do it would be like this:\n\nmean(my_df[my_df$conditions==\"A\",]$scores)\n\n[1] 10.58511\n\nmean(my_df[my_df$conditions==\"B\",]$scores)\n\n[1] 8.018306\n\nmean(my_df[my_df$conditions==\"C\",]$scores)\n\n[1] 10.29478\n\n# and then keep going\n\nIt is evident that no individual or entity is willing to assume the responsibility of performing this task. It is therefore prudent to encapsulate this functionality, and R provides us with the necessary tools to automate this functionality.\n\n\nWe can easily do everything all at once using the group_by and summarise function from the dplyr package. Just watch\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmy_df %&gt;%\n  group_by(conditions) %&gt;%\n  summarise(means = mean(scores))\n\n# A tibble: 10 × 2\n   conditions means\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 A          10.6 \n 2 B           8.02\n 3 C          10.3 \n 4 D           8.69\n 5 E           9.51\n 6 F          11.1 \n 7 G           9.51\n 8 H           9.57\n 9 I          11.3 \n10 J          12.0 \n\n\nA few points require further consideration. Firstly, the printout of this was of an inferior quality. A solution to this issue is to create a new variable containing the results of the code and then use the knitr::kable function to print the variable in a more aesthetically pleasing manner when the document is compiled.\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\n\n\n\n\nA\n10.585114\n\n\nB\n8.018306\n\n\nC\n10.294783\n\n\nD\n8.687497\n\n\nE\n9.506123\n\n\nF\n11.071491\n\n\nG\n9.512394\n\n\nH\n9.571136\n\n\nI\n11.284107\n\n\nJ\n12.012939\n\n\n\n\n\n\n\n\nThe most advantageous aspect of the dplyr method is that it permits the addition of multiple functions, resulting in the generation of multiple summary statistics in a unified format. To illustrate this, consider the calculation of the standard deviation:\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores),\n                         sds = sd(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\nsds\n\n\n\n\nA\n10.585114\n5.679876\n\n\nB\n8.018306\n4.137335\n\n\nC\n10.294783\n5.358272\n\n\nD\n8.687497\n4.638121\n\n\nE\n9.506123\n3.122304\n\n\nF\n11.071491\n5.047547\n\n\nG\n9.512394\n4.854704\n\n\nH\n9.571136\n6.591424\n\n\nI\n11.284107\n5.762363\n\n\nJ\n12.012939\n5.145721\n\n\n\n\n\nFurthermore, the minimum and maximum values will be included.\n\nsummary_df &lt;- my_df %&gt;%\n               group_by(conditions) %&gt;%\n               summarise(means = mean(scores),\n                         sds = sd(scores),\n                         min = min(scores),\n                         max = max(scores))\n\nknitr::kable(summary_df)\n\n\n\n\nconditions\nmeans\nsds\nmin\nmax\n\n\n\n\nA\n10.585114\n5.679876\n3.6182982\n20.44245\n\n\nB\n8.018306\n4.137335\n0.4974302\n12.28050\n\n\nC\n10.294783\n5.358272\n2.5335906\n15.91243\n\n\nD\n8.687497\n4.638121\n0.0110298\n15.25871\n\n\nE\n9.506123\n3.122304\n5.3783867\n15.37293\n\n\nF\n11.071491\n5.047547\n0.1306032\n18.75173\n\n\nG\n9.512394\n4.854704\n3.1293046\n17.04708\n\n\nH\n9.571136\n6.591424\n-1.0027310\n19.54346\n\n\nI\n11.284107\n5.762363\n3.4570481\n18.97414\n\n\nJ\n12.012939\n5.145721\n5.6354111\n20.06696\n\n\n\n\n\n\n\n\n\nHaving established the methodology for obtaining descriptive statistics from R, we may now proceed to apply this methodology to a real data set. We will now proceed to inquire about the gapminder data.\n\nlibrary(gapminder)\ngapminder_df &lt;- gapminder\n\nNote: The code will only function properly if the gapminder package has been installed. It is imperative that the user is connected to the internet prior to commencing the installation process. To do so, navigate to the Packages tab, located in the bottom right panel, and select the option to install. Subsequently, a search for the gapminder package should be conducted, after which it should be selected and installed.\n\n\nCopy the code from the last part of descriptives using dplyr, then change the names like this:\n\nsummary_df &lt;- gapminder_df %&gt;%\n               group_by(continent) %&gt;%\n               summarise(means = mean(lifeExp),\n                         sds = sd(lifeExp),\n                         min = min(lifeExp),\n                         max = max(lifeExp))\n\nknitr::kable(summary_df)\n\n\n\n\ncontinent\nmeans\nsds\nmin\nmax\n\n\n\n\nAfrica\n48.86533\n9.150210\n23.599\n76.442\n\n\nAmericas\n64.65874\n9.345088\n37.579\n80.653\n\n\nAsia\n60.06490\n11.864532\n28.801\n82.603\n\n\nEurope\n71.90369\n5.433178\n43.585\n81.757\n\n\nOceania\n74.32621\n3.795611\n69.120\n81.235\n\n\n\n\n\n\n\n\n\nComplete the generalization exercise described in your R Markdown document for this lab.\n\nWhat is the mean, standard deviation, minimum and maximum life expectancy for all the gapminder data (across all the years and countries). Hint: do not use group_by\nWhat is the mean, standard deviation, minimum and maximum life expectancy for all of the continents in 2007, the most recent year in the dataset. Hint: add another pipe using filter(year==2007) %&gt;%\n\n\n\n\nComplete the writing assignment described in your R Markdown document for this lab. When you have finished everything. Knit the document and hand in your stuff (you can submit your .RMD file to blackboard if it does not knit.)\nYour writing assignment is to answer these questions in full sentences using simple plain langauge:\n\nDefine the mode.\nExplain what would need to happen in order for a set of numbers to have two modes\nDefine the median\nDefine the mean\nDefine the range\nWhen calculating the standard deviation, explain what the difference scores represent\nExplain why the difference scores are squared when calculating the standard deviation\nIf one set of numbers had a standard deviation of 5, and another had a standard deviation of 10, which set of numbers would have greater variance, explain why.\n\n\n\n\nNow let’s use a real dataset to calculate the same measures of central tendency and variability as in the previous example, but with the addition of a histogram to visualize the distribution and relate back to the descriptive statistics. Here is a link to the life expectancy dataset we used for our graphing tutorial. It is named life_expectancy.csv.\nSuppose we wanted to know about life expectancy around the world in 2018. This will include calculating descriptive statistics and graphing a histogram to examine the distribution of our data. R allows us to handle these tasks efficiently with a few lines of code.\n\n\n\nLoad the Data:\n\nFirst, ensure you have the dataset life_expectancy.csv in your working directory.\nLoad the data into R.\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load the data\nlife_expectancy &lt;- read.csv(\"data/life_expectancy.csv\")\nCalculate Descriptive Statistics:\n\nCalculate the measures of central tendency (mean, median, mode) and measures of variability (range, standard deviation, variance) for life expectancy in 2018.\n\n# Filter for the year 2018\nlife_2018 &lt;- life_expectancy %&gt;% filter(Year == 2018) %&gt;% select(life_expectancy)\n\n# Calculate descriptive statistics\n\n# Summarize the results\nCreate a Histogram:\n\nPlot a histogram to visualize the distribution of life expectancy in 2018, and overlay a normal curve.\n\n# Plot the histogram with a normal curve\nggplot(life_2018, aes(x = life_expectancy)) +\n  geom_histogram(aes(y = ..density..), binwidth = 2, fill = \"skyblue\", color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = mean_life, sd = sd_life), color = \"red\", size = 1) +\n  labs(title = \"Histogram of Life Expectancy in 2018\",\n       x = \"Life Expectancy\",\n       y = \"Density\") +\n  theme_minimal()\n\nThis process will produce a histogram displaying the distribution of life expectancy in 2018 with a superimposed normal curve for comparison.\n\n\n\nThink about what the mean, median, and mode indicate about the shape of the distribution. Is this confirmed when you look at the histogram? How does the shape of this distribution compare to the symmetrical normal distribution that is superimposed over it? The histogram helps visualize the skewness and spread of the data, providing a deeper understanding of the life expectancy distribution in 2018.\n\n\n\n\n\n\nUsing the life expectancy data set, produce a table of output showing the descriptive statistics (measures of central tendency and variability) for both years 1800 and 1934 (during the Great Depression).\nPlot histograms of life expectancy for both years. How are these distributions different? (Hint: Plot these on the same axes so that they are comparable)."
  }
]